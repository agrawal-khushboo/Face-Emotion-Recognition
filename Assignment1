from os import listdir
from PIL import Image
import numpy as np
from numpy import linalg as LA
import math

# The relative path to your CAFE-Gamma dataset
data_dir = "./CAFE/"

# Dictionary of semantic "label" to emotions
emotion_dict = {"h": "happy", "ht": "happy with teeth", "m": "maudlin",
    "s": "surprise", "f": "fear", "a": "anger", "d": "disgust", "n": "neutral"}
Happydata=[]
saddata=[]

def load_data(data_dir):
    """ Load all PGM images stored in your data directory into a list of NumPy
    arrays with a list of corresponding labels.

    Args:
        data_dir: The relative filepath to the CAFE dataset.
    Returns:
        images: A list containing every image in CAFE as an array.
        labels: A list of the corresponding labels (filenames) for each image.
    """
    # Get the list of image file names
    all_files = listdir(data_dir)

    # Store the images as arrays and their labels in two lists
    images = []
    labels = []
    

    for file in all_files:
        
        # Load in the files as PIL images and convert to NumPy arrays
        if '_ht' in file:
            img = Image.open(data_dir + file)
            Happydata.append(np.array(img))
            images.append(np.array(img))
            labels.append(file)
        elif '_m' in file:
            img = Image.open(data_dir + file)
            saddata.append(np.array(img))
            images.append(np.array(img))
            labels.append(file)
        
        elif '_h' in file or '_n' in file:
            continue
        else:
            img = Image.open(data_dir + file)
            images.append(np.array(img))
            labels.append(file)

    print("Total number of images:", len(images), "and labels:", len(labels))

    return images, labels


def PCA(data, dims_rescaled_data):
    """
    returns: data transformed in 2 dims/columns + regenerated original data
    pass in: data as 2D NumPy array
    """
    m, n = data.shape
    # mean center the data
    data = data - np.mean(data,axis=0)
    # calculate the covariance matrix
    R = np.matmul(data,data.T)
    # calculate eigenvectors & eigenvalues of the covariance matrix
    # use 'eigh' rather than 'eig' since R is symmetric,
    # the . gain is substantial
    evals, evecs = LA.eigh(R)
    # sort eigenvalue in decreasing order
    idx = np.argsort(evals)[::-1]
    evecs = evecs[:,idx]
    # sort eigenvectors according to same index
    evals = evals[idx]
    # select the first n eigenvectors (n is desired dimension
    # of rescaled data array, or dims_rescaled_data)
    evecs = evecs[:, :dims_rescaled_data]
#     print(len(evecs))
    # carry out the transformation on the data using eigenvectors
    # and return the re-scaled data, eigenvalues, and eigenvectors
    eigen_vectors = np.dot(data.T,evecs)
    for i in range(eigen_vectors.shape[1]):
        sum = np.linalg.norm(eigen_vectors[:,i])
        eigen_vectors[:,i] = eigen_vectors[:,i]/sum
#         print(evals[i])
        eigen_vectors[:,i] = eigen_vectors[:,i]/math.sqrt(evals[i])

    
    return data, evals, eigen_vectors


def display_face(img):
    """ Display the input image and optionally save as a PNG.

    Args:
        img: The NumPy array or image to display

    Returns: None
    """
    # Convert img to PIL Image object (if it's an ndarray)
    if type(img) == np.ndarray:
        print("Converting from array to PIL Image")
        img = Image.fromarray(img)

    # Display the image
    img.show()
    
def reduce_dimensions(Data):
    Data_new = []
    for image in Data:
        a = image.flatten()
        Data_new.append(a)

    Data_new = np.matrix(Data_new)
    print(Data_new.shape)
    _,ev,ei = PCA(Data_new,len(Data)-1)
    reduced_data = np.dot(Data_new,ei)
    return reduced_data,ei

images,labels = load_data(data_dir = "./CAFE/")
Data,ei = reduce_dimensions(images)


def sigmoid(value):
    return 1/(1+np.exp(-value))
def lossfunction(validation,validationlabel,weights):
    loss  = 0
    for i in range(len(validation)):
        value=np.dot(validation[i],weights)
        predict=sigmoid(value)
        loss += validationlabel[i]*math.log(predict) + (1-validationlabel[i])*math.log(1-predict)
    return -loss

def logistic_regression(features, target,epochs,rate,validation,validationlabel):
    weights= np.zeros(features.shape[1])
    loss= lossfunction(validation,validationlabel,weights)
    for epoch in range(epochs):
        value= np.dot(features,weights)
        predict=sigmoid(value)
        gradient= np.dot((target-predict),features)
        new_weights= weights+rate*gradient
        new_loss= lossfunction(validation,validationlabel,weights)
        if new_loss<loss:
            weights=new_weights
    return weights
        
for i in range(10):
    train=[]
    validation=[]
    trainlabel=[]
    testlabel=[]
    newvalidation=[]
    validationlabel=[]
    test=[]
    if i<9:
        for k in range(10):
            if k==i:
                test.append(Happydata[k])
                testlabel.append(1)
                test.append(saddata[k])
                testlabel.append(0)
            elif k==i+1:
                validation.append(Happydata[k])
                validationlabel.append(1)
                validation.append(saddata[k])
                validationlabel.append(0)
            else:
                train.append(Happydata[k])
                trainlabel.append(1)
                train.append(saddata[k])
                trainlabel.append(0)
    else:
        test.append(Happydata[k])
        testlabel.append(1)
        test.append(saddata[k])
        testlabel.append(0)
        validation.append(Happydata[0])
        validationlabel.append(1)
        validation.append(saddata[0])
        validationlabel.append(0)
        for k in range(1,9):
            train.append(Happydata[k])
            trainlabel.append(1)
            train.append(saddata[k])
            trainlabel.append(0)
    train,eigenvec=reduce_dimensions(train)
#     validation=np.matrix(validation)
    for image in validation:
        newvalidation.append(image.flatten())
        
    newvalidation = np.matrix(newvalidation)
    
    newvalidation=np.matmul(newvalidation,eigenvec)
    print(newvalidation.shape)
#     validation= validation
#     logistic_regression(train,trainlabel,10,0.1)
    w=logistic_regression(train,trainlabel,10,0.1,newvalidation,validationlabel)
    print(w)

    
    
    
    
    


